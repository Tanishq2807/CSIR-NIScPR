{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.599213Z",
     "start_time": "2025-11-12T13:31:37.586779Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from typing import Any, Tuple"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.611859Z",
     "start_time": "2025-11-12T13:31:37.606077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- CONFIG ----------\n",
    "CSV_PATH   = \"/Users/tanishq/PycharmProjects/NIScPR/FinTech/DerwentData_TS/dfa/MainData.csv\"\n",
    "ID_COL     = \"Publication Number\"\n",
    "DATE_COL   = \"Application Date\"\n",
    "\n",
    "INDICATORS = [\n",
    "    \"DWPI Count of Family Members\",\n",
    "    \"DWPI Count of Family Countries/Regions\",\n",
    "    \"Assignee Count\",\n",
    "    \"Inventor Count\",\n",
    "    \"Claims Count\",\n",
    "    \"Legal Years Remaining\",\n",
    "    \"IPC Count\",\n",
    "]\n",
    "\n",
    "TRAIN_START = pd.Timestamp(\"2000-01-01\")\n",
    "TRAIN_END   = pd.Timestamp(\"2022-12-31\")\n",
    "SCORE_START = pd.Timestamp(\"2023-01-01\")\n",
    "SCORE_END   = pd.Timestamp(\"2024-12-31\")\n",
    "\n",
    "RESAMPLE_RULE = \"M\"     # month-end (canonical pandas alias)\n",
    "MAX_K_FACTORS = len(INDICATORS)-1\n",
    "FACTOR_ORDER  = 0\n",
    "ERROR_COV     = \"scalar\"\n",
    "TOP_PCT       = 0.05"
   ],
   "id": "3051f5740bff9d04",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.618803Z",
     "start_time": "2025-11-12T13:31:37.616343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optionally stabilize heavy-tailed counts (leave empty to keep raw)\n",
    "LOG1P_VARS: list[str] = []  # e.g., [\"Count of Citing Patents\", \"Claims Count\", \"IPC Count\"]"
   ],
   "id": "3725c2ff9f7c2013",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.630292Z",
     "start_time": "2025-11-12T13:31:37.627091Z"
    }
   },
   "cell_type": "code",
   "source": "# ---------- UTILS ----------",
   "id": "d8b981ec606ced3",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.640023Z",
     "start_time": "2025-11-12T13:31:37.637748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def winsorize(s: pd.Series, p: float = 0.01) -> pd.Series:\n",
    "    # Safe quantiles even with all-NaN/constant series\n",
    "    if s.notna().sum() == 0:\n",
    "        return s\n",
    "    lo, hi = s.quantile(p), s.quantile(1 - p)\n",
    "    if pd.isna(lo) or pd.isna(hi) or lo == hi:\n",
    "        return s\n",
    "    return s.clip(lo, hi)"
   ],
   "id": "d17dedb76b77c8fc",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.647955Z",
     "start_time": "2025-11-12T13:31:37.644763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def robust_standardize_train(ts_train: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
    "    mean = ts_train.mean(skipna=True)\n",
    "    std = ts_train.std(ddof=1, skipna=True).replace(0, np.nan)\n",
    "    return (ts_train - mean) / std, mean, std"
   ],
   "id": "9e051166d76fb972",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.656523Z",
     "start_time": "2025-11-12T13:31:37.652230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def try_fit_dfa(mod: sm.tsa.DynamicFactor) -> Any:\n",
    "    start_params = None\n",
    "    # EM init if available\n",
    "    try:\n",
    "        if hasattr(mod, \"fit_em\"):\n",
    "            res0 = mod.fit_em(maxiter=100, disp=False)\n",
    "            start_params = getattr(res0, \"params\", None)\n",
    "    except Exception:\n",
    "        start_params = None\n",
    "    # Model-provided starts\n",
    "    if start_params is None:\n",
    "        try:\n",
    "            start_params = mod.start_params\n",
    "        except Exception:\n",
    "            start_params = None\n",
    "    # Optimizer cascade\n",
    "    for method, kw in [\n",
    "        (\"lbfgs\", dict(maxiter=2000)),\n",
    "        (\"powell\", dict(maxiter=400)),\n",
    "        (\"nm\", dict(maxiter=2000)),\n",
    "    ]:\n",
    "        try:\n",
    "            return mod.fit(start_params=start_params, method=method, disp=False, **kw)\n",
    "        except Exception:\n",
    "            continue\n",
    "    # Last-ditch: powell then lbfgs with its params\n",
    "    try:\n",
    "        res1 = mod.fit(start_params=start_params, method=\"powell\", maxiter=400, disp=False)\n",
    "        return mod.fit(start_params=getattr(res1, \"params\", None), method=\"lbfgs\", maxiter=2000, disp=False)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"DFA fit failed with all methods: {e}\")"
   ],
   "id": "e8d04d5ef214afa2",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.662582Z",
     "start_time": "2025-11-12T13:31:37.660149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _safe_converged(res: Any) -> bool:\n",
    "    ret = getattr(res, \"mle_retvals\", None)\n",
    "    if isinstance(ret, dict) and \"converged\" in ret:\n",
    "        return bool(ret[\"converged\"])\n",
    "    return bool(getattr(res, \"converged\", False))"
   ],
   "id": "8f174b937a4dfcaf",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.668964Z",
     "start_time": "2025-11-12T13:31:37.666415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _load_name_candidates(f_idx: int, var_idx: int, var_name: str | None) -> list[str]:\n",
    "    # Common historical parameter name formats across statsmodels versions\n",
    "    cands = [\n",
    "        f\"loading.f{f_idx}.y{var_idx}\",\n",
    "        f\"loading.f{f_idx}.{var_idx}\",\n",
    "        f\"loading.L[{var_idx-1},{f_idx-1}]\",\n",
    "    ]\n",
    "    if var_name:\n",
    "        cands += [\n",
    "            f\"loading.f{f_idx}.{var_name}\",\n",
    "            f\"loading.f{f_idx}.y{var_name}\",\n",
    "            f\"loading.{var_name}.f{f_idx}\",\n",
    "        ]\n",
    "    return cands"
   ],
   "id": "13fb8696d4fb34b5",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.677332Z",
     "start_time": "2025-11-12T13:31:37.672829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_loadings(res: Any, indicators: list[str], k: int, endog_names: list[str]) -> np.ndarray:\n",
    "    # Map parameter name -> value robustly\n",
    "    param_names = list(getattr(res, \"param_names\", []))\n",
    "    params = getattr(res, \"params\", None)\n",
    "    if params is None or len(param_names) != len(params):\n",
    "        try:\n",
    "            s = res.params  # pandas Series in some versions\n",
    "            param_names = list(s.index)\n",
    "            params = s.values\n",
    "        except Exception:\n",
    "            pass\n",
    "    if params is None:\n",
    "        raise RuntimeError(\"Could not access fitted parameter vector.\")\n",
    "    name2param = {pn: float(params[i]) for i, pn in enumerate(param_names)}\n",
    "\n",
    "    load_mat = np.zeros((len(indicators), k), dtype=float)\n",
    "    for f in range(1, k + 1):\n",
    "        for i, _col in enumerate(indicators, start=1):\n",
    "            var_name = None\n",
    "            try:\n",
    "                if isinstance(endog_names, (list, tuple)) and len(endog_names) >= i:\n",
    "                    var_name = endog_names[i - 1]\n",
    "            except Exception:\n",
    "                var_name = None\n",
    "            candidates = _load_name_candidates(f, i, var_name)\n",
    "            val = None\n",
    "            for cname in candidates:\n",
    "                if cname in name2param:\n",
    "                    val = name2param[cname]\n",
    "                    break\n",
    "            if val is None:\n",
    "                # Fuzzy fallback\n",
    "                prefix = f\"loading.f{f}\"\n",
    "                matches = [kname for kname in name2param\n",
    "                           if kname.startswith(prefix) and (\n",
    "                               kname.endswith(f\".y{i}\") or\n",
    "                               kname.endswith(f\".{i}\") or\n",
    "                               (var_name and var_name in kname)\n",
    "                           )]\n",
    "                if matches:\n",
    "                    val = name2param[matches[0]]\n",
    "            if val is None:\n",
    "                raise RuntimeError(f\"Missing loading for factor {f}, variable index {i} ({_col}).\")\n",
    "            load_mat[i - 1, f - 1] = val\n",
    "    return load_mat"
   ],
   "id": "cfee5546df134af9",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.683325Z",
     "start_time": "2025-11-12T13:31:37.680928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rowwise_weighted_sum_nan_safe(Z: np.ndarray, weights: np.ndarray) -> np.ndarray:\n",
    "    W = weights.reshape(1, -1)\n",
    "    mask = ~np.isnan(Z)\n",
    "    numer = np.nan_to_num(Z) * W\n",
    "    denom = (W * mask).sum(axis=1, keepdims=True)\n",
    "    denom[denom == 0] = np.nan\n",
    "    return (numer.sum(axis=1, keepdims=True) / denom).ravel()"
   ],
   "id": "1554069fdd47838c",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.689399Z",
     "start_time": "2025-11-12T13:31:37.687604Z"
    }
   },
   "cell_type": "code",
   "source": "# ---------- MAIN PIPELINE ----------",
   "id": "8eba0105ea85ba15",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.792223Z",
     "start_time": "2025-11-12T13:31:37.693391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "# df = df.dropna(subset=[DATE_COL])"
   ],
   "id": "39cbc24b4dccf4d6",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.802156Z",
     "start_time": "2025-11-12T13:31:37.798962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for c in INDICATORS:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")"
   ],
   "id": "9a69d1c820788618",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.815372Z",
     "start_time": "2025-11-12T13:31:37.805769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"date range:\", df[DATE_COL].min(), \"->\", df[DATE_COL].max())\n",
    "print(\"na ratio per column:\\n\", df[INDICATORS].isna().mean().sort_values(ascending=False))"
   ],
   "id": "1ecea263984776ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date range: 2000-05-15 00:00:00 -> 2024-12-31 00:00:00\n",
      "na ratio per column:\n",
      " DWPI Count of Family Members              0.0\n",
      "DWPI Count of Family Countries/Regions    0.0\n",
      "Assignee Count                            0.0\n",
      "Inventor Count                            0.0\n",
      "Claims Count                              0.0\n",
      "Legal Years Remaining                     0.0\n",
      "IPC Count                                 0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.843750Z",
     "start_time": "2025-11-12T13:31:37.824826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "monthly = (df\n",
    "           .set_index(DATE_COL)\n",
    "           .sort_index()[INDICATORS]\n",
    "           .resample(RESAMPLE_RULE)\n",
    "           .sum(min_count=1))\n",
    "\n",
    "ts = monthly.loc[TRAIN_START:TRAIN_END]"
   ],
   "id": "ddfc2fde5e0a17b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/zsswp6xx6bb2_yfyprkybnfc0000gn/T/ipykernel_24107/2372555477.py:4: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  .resample(RESAMPLE_RULE)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.856345Z",
     "start_time": "2025-11-12T13:31:37.853655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Light imputation to avoid full-row drops:\n",
    "ts_imp = ts.copy()\n",
    "# Carry small gaps; leave long gaps as NaN\n",
    "ts_imp = ts_imp.ffill(limit=2).bfill(limit=2)"
   ],
   "id": "efa83516b8bb3dfd",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.863713Z",
     "start_time": "2025-11-12T13:31:37.859724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "med = ts_imp.median(skipna=True)\n",
    "iqr = ts_imp.quantile(0.75) - ts_imp.quantile(0.25)\n",
    "scale = iqr.replace(0, np.nan)\n",
    "ts_train_std = (ts_imp - med) / scale"
   ],
   "id": "695f2f8fea60a0f6",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.870663Z",
     "start_time": "2025-11-12T13:31:37.867608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"train shape:\", ts_train_std.shape)\n",
    "print(\"rows all-na:\", int(ts_train_std.isna().all(axis=1).sum()), \"of\", len(ts_train_std))\n",
    "print(\"cols all-na:\", list(ts_train_std.columns[ts_train_std.isna().all()]))"
   ],
   "id": "23ae83559aa706c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (272, 7)\n",
      "rows all-na: 0 of 272\n",
      "cols all-na: []\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.904904Z",
     "start_time": "2025-11-12T13:31:37.901328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts_train_std = ts_train_std.dropna(how=\"all\")\n",
    "\n",
    "if len(ts_train_std) < (FACTOR_ORDER + MAX_K_FACTORS + 5):\n",
    "    raise ValueError(\"Not enough timesteps after cleaning. Reduce k_factors or widen TRAIN window.\")"
   ],
   "id": "c7001da6d95c60c8",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:37.916445Z",
     "start_time": "2025-11-12T13:31:37.914127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts_train = ts.loc[TRAIN_START:TRAIN_END]\n",
    "if ts_train.shape[0] < 18:\n",
    "    raise ValueError(f\"Too few monthly periods in training window {TRAIN_START.date()}–{TRAIN_END.date()}.\")"
   ],
   "id": "d48a4bdfeb19dc14",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:53.868353Z",
     "start_time": "2025-11-12T13:31:37.920341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def try_fit_dfa(mod):\n",
    "    # Fit with missing='drop' so the Kalman filter ignores NA entries rather than you pre-dropping entire rows\n",
    "    return mod.fit(\n",
    "        disp=False,\n",
    "        maxiter=2000,\n",
    "        cov_type=\"opg\",\n",
    "        enforce_stationarity=True,\n",
    "        enforce_invertibility=True,  # pass here, not in constructor\n",
    "        missing=\"drop\"\n",
    "    )\n",
    "\n",
    "bic, best = {}, {}\n",
    "for k in range(1, MAX_K_FACTORS + 1):\n",
    "    # Remove invalid kw from constructor\n",
    "    mod = sm.tsa.DynamicFactor(\n",
    "        endog=ts_train_std,\n",
    "        k_factors=k,\n",
    "        factor_order=FACTOR_ORDER,\n",
    "        error_cov_type=ERROR_COV,\n",
    "    )\n",
    "    try:\n",
    "        res = try_fit_dfa(mod)\n",
    "        if res.mle_retvals.get(\"converged\", False) and np.isfinite(getattr(res, \"bic\", np.inf)):\n",
    "            bic[k] = float(res.bic)\n",
    "            best[k] = res\n",
    "            print(f\"[INFO] k={k}: BIC={res.bic:.2f}, converged=True\")\n",
    "        else:\n",
    "            print(f\"[WARN] k={k}: skipped (converged={res.mle_retvals.get('converged', False)}, finite_bic={np.isfinite(getattr(res,'bic', np.inf))})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] k={k}: fitting failed -> {e}\")\n",
    "\n",
    "if not bic:\n",
    "    raise RuntimeError(\"All candidate DFA fits failed. Check data span, NA rate, and k_factors.\")\n",
    "\n",
    "k_star = min(bic, key=bic.get)\n",
    "res_best = best[k_star]\n",
    "print(\"Selected k =\", k_star)"
   ],
   "id": "9c0dc30335d18429",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:21: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: missing. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] k=1: BIC=5767.19, converged=True"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:21: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: missing. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] k=2: BIC=4959.07, converged=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:21: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: missing. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] k=3: BIC=4230.11, converged=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:21: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: missing. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:21: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: missing. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] k=4: skipped (converged=False, finite_bic=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/optimizer.py:21: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: missing. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] k=5: skipped (converged=False, finite_bic=True)\n",
      "[WARN] k=6: skipped (converged=False, finite_bic=True)\n",
      "Selected k = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanishq/PycharmProjects/project1/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:53.898425Z",
     "start_time": "2025-11-12T13:31:53.895993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # --- Model selection by BIC ---\n",
    "# bic, best = {}, {}\n",
    "# for k in range(1, MAX_K_FACTORS + 1):\n",
    "#     mod = sm.tsa.DynamicFactor(\n",
    "#         ts_train_std,\n",
    "#         k_factors=k,\n",
    "#         factor_order=FACTOR_ORDER,\n",
    "#         error_cov_type=ERROR_COV,\n",
    "#         enforce_stationarity=True,\n",
    "#         enforce_invertibility=True,\n",
    "#     )\n",
    "#     try:\n",
    "#         res = try_fit_dfa(mod)\n",
    "#         converged = _safe_converged(res)\n",
    "#         rbic = getattr(res, \"bic\", np.inf)\n",
    "#         finite_bic = np.isfinite(rbic)\n",
    "#         if converged and finite_bic:\n",
    "#             bic[k] = float(rbic)\n",
    "#             best[k] = res\n",
    "#             print(f\"[INFO] k={k}: BIC={rbic:.2f}, converged={converged}\")\n",
    "#         else:\n",
    "#             print(f\"[WARN] k={k}: skipped (converged={converged}, finite_bic={finite_bic})\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"[WARN] k={k}: fitting failed -> {e}\")\n",
    "#\n",
    "# if not bic:\n",
    "#     raise RuntimeError(\"All candidate DFA fits failed or did not converge with finite BIC. \"\n",
    "#                        \"Action: reduce MAX_K_FACTORS, simplify model, or lengthen TRAIN window.\")"
   ],
   "id": "de899a99127d2ae3",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:53.906063Z",
     "start_time": "2025-11-12T13:31:53.904294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimal_k = min(bic, key=bic.get)\n",
    "res = best[optimal_k]\n",
    "print(f\"[OK] Selected k={optimal_k} with BIC={bic[optimal_k]:.2f}\")"
   ],
   "id": "79614d4def74202d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Selected k=3 with BIC=4230.11\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:53.911869Z",
     "start_time": "2025-11-12T13:31:53.909295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Loadings -> indicator weights ---\n",
    "try:\n",
    "    endog_names = list(getattr(res.model, \"endog_names\", []))\n",
    "    if isinstance(endog_names, str):\n",
    "        endog_names = [endog_names]\n",
    "except Exception:\n",
    "    endog_names = []\n",
    "load_mat = extract_loadings(res, INDICATORS, optimal_k, endog_names=endog_names)\n",
    "\n",
    "var_contrib = (load_mat ** 2).sum(axis=1)\n",
    "total = var_contrib.sum()\n",
    "if not np.isfinite(total) or total <= 0:\n",
    "    raise RuntimeError(\"Invalid variance contributions from loadings.\")\n",
    "weights = var_contrib / total"
   ],
   "id": "9c8e9e9aa2458a81",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/zsswp6xx6bb2_yfyprkybnfc0000gn/T/ipykernel_24107/4098707077.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  name2param = {pn: float(params[i]) for i, pn in enumerate(param_names)}\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:53.916888Z",
     "start_time": "2025-11-12T13:31:53.914738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Export weights (all 10 indicators) ---\n",
    "weights_df = pd.DataFrame({\n",
    "    \"Indicator\": INDICATORS,\n",
    "    \"VarianceContribution\": var_contrib,\n",
    "    \"Weight\": weights\n",
    "}).sort_values(\"Weight\", ascending=False).reset_index(drop=True)"
   ],
   "id": "a832a57b18e4c526",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:53.924564Z",
     "start_time": "2025-11-12T13:31:53.920803Z"
    }
   },
   "cell_type": "code",
   "source": "weights_df",
   "id": "1256363e97c37782",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                Indicator  VarianceContribution    Weight\n",
       "0  DWPI Count of Family Countries/Regions             68.290157  0.294948\n",
       "1            DWPI Count of Family Members             35.682777  0.154116\n",
       "2                   Legal Years Remaining             32.616530  0.140872\n",
       "3                          Inventor Count             31.540156  0.136223\n",
       "4                            Claims Count             25.335412  0.109425\n",
       "5                          Assignee Count             19.296404  0.083342\n",
       "6                               IPC Count             18.771136  0.081073"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator</th>\n",
       "      <th>VarianceContribution</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWPI Count of Family Countries/Regions</td>\n",
       "      <td>68.290157</td>\n",
       "      <td>0.294948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWPI Count of Family Members</td>\n",
       "      <td>35.682777</td>\n",
       "      <td>0.154116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal Years Remaining</td>\n",
       "      <td>32.616530</td>\n",
       "      <td>0.140872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inventor Count</td>\n",
       "      <td>31.540156</td>\n",
       "      <td>0.136223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Claims Count</td>\n",
       "      <td>25.335412</td>\n",
       "      <td>0.109425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assignee Count</td>\n",
       "      <td>19.296404</td>\n",
       "      <td>0.083342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IPC Count</td>\n",
       "      <td>18.771136</td>\n",
       "      <td>0.081073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:53.954696Z",
     "start_time": "2025-11-12T13:31:53.929817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Scoring 2023–2024 on TRAIN scale (row-wise) ---\n",
    "df_train_rows = df[df[DATE_COL].between(TRAIN_START, TRAIN_END, inclusive=\"both\")]\n",
    "train_row_mean = df_train_rows[INDICATORS].mean(skipna=True)\n",
    "train_row_std  = df_train_rows[INDICATORS].std(ddof=1, skipna=True).replace(0, np.nan)\n",
    "\n",
    "df_eval = df[df[DATE_COL].between(SCORE_START, SCORE_END, inclusive=\"both\")].copy()\n",
    "if df_eval.empty:\n",
    "    raise ValueError(f\"No rows in scoring window {SCORE_START.date()}–{SCORE_END.date()}.\")\n",
    "\n",
    "Zcols = []\n",
    "for c in INDICATORS:\n",
    "    z = (df_eval[c].astype(float) - train_row_mean[c]) / train_row_std[c]\n",
    "    zname = f\"Z::{c}\"\n",
    "    df_eval[zname] = z\n",
    "    Zcols.append(zname)\n",
    "\n",
    "Z = df_eval[Zcols].to_numpy(dtype=float)\n",
    "qi = rowwise_weighted_sum_nan_safe(Z, weights)\n",
    "df_eval[\"QualityIndex\"] = qi\n",
    "\n",
    "df_eval = df_eval.sort_values(\"QualityIndex\", ascending=False).reset_index(drop=True)\n",
    "k_top = int(np.ceil(TOP_PCT * len(df_eval))) if len(df_eval) else 0\n",
    "df_eval[\"Top5pct\"] = False\n",
    "if k_top > 0:\n",
    "    df_eval.loc[:k_top - 1, \"Top5pct\"] = True"
   ],
   "id": "3a5e2927f5a1c056",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:54.004370Z",
     "start_time": "2025-11-12T13:31:53.977420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Save & print summaries ---\n",
    "train_tag = f\"{TRAIN_START.year}_{TRAIN_END.year}\"\n",
    "weights_path = f\"dfa_weights_{train_tag}.csv\"\n",
    "scores_path  = \"quality_scores_2023_24.csv\"\n",
    "\n",
    "weights_df.to_csv(weights_path, index=False)\n",
    "df_eval[[ID_COL, DATE_COL, \"QualityIndex\", \"Top5pct\"]].to_csv(scores_path, index=False)\n",
    "\n",
    "print(\"\\n=== DFA Summary ===\")\n",
    "print(f\"Train window: {TRAIN_START.date()} to {TRAIN_END.date()}\")\n",
    "print(f\"Score window: {SCORE_START.date()} to {SCORE_END.date()}\")\n",
    "print(f\"Candidates tried (k): {list(bic.keys())}\")\n",
    "print(f\"Optimal k: {optimal_k}  |  Converged: {_safe_converged(res)}\")\n",
    "print(f\"Saved weights -> {os.path.abspath(weights_path)}\")\n",
    "print(f\"Saved scores  -> {os.path.abspath(scores_path)}\")\n",
    "\n",
    "print(\"\\nIndicator weights (variance share; higher = more influence):\")\n",
    "print(weights_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nWeights in original indicator order:\")\n",
    "for ind, w in zip(INDICATORS, weights):\n",
    "    print(f\"{ind}: {w:.6f}\")\n",
    "\n",
    "print(\"\\nTop 10 by QualityIndex:\")\n",
    "print(df_eval[[ID_COL, \"QualityIndex\", \"Top5pct\"]].head(10).to_string(index=False))"
   ],
   "id": "63512df08a6aa259",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DFA Summary ===\n",
      "Train window: 2000-01-01 to 2022-12-31\n",
      "Score window: 2023-01-01 to 2024-12-31\n",
      "Candidates tried (k): [1, 2, 3]\n",
      "Optimal k: 3  |  Converged: True\n",
      "Saved weights -> /Users/tanishq/PycharmProjects/NIScPR/FinTech/DerwentData_TS/dfa/7 indicators/dfa_weights_2000_2022.csv\n",
      "Saved scores  -> /Users/tanishq/PycharmProjects/NIScPR/FinTech/DerwentData_TS/dfa/7 indicators/quality_scores_2023_24.csv\n",
      "\n",
      "Indicator weights (variance share; higher = more influence):\n",
      "                             Indicator  VarianceContribution   Weight\n",
      "DWPI Count of Family Countries/Regions             68.290157 0.294948\n",
      "          DWPI Count of Family Members             35.682777 0.154116\n",
      "                 Legal Years Remaining             32.616530 0.140872\n",
      "                        Inventor Count             31.540156 0.136223\n",
      "                          Claims Count             25.335412 0.109425\n",
      "                        Assignee Count             19.296404 0.083342\n",
      "                             IPC Count             18.771136 0.081073\n",
      "\n",
      "Weights in original indicator order:\n",
      "DWPI Count of Family Members: 0.154116\n",
      "DWPI Count of Family Countries/Regions: 0.294948\n",
      "Assignee Count: 0.083342\n",
      "Inventor Count: 0.136223\n",
      "Claims Count: 0.109425\n",
      "Legal Years Remaining: 0.140872\n",
      "IPC Count: 0.081073\n",
      "\n",
      "Top 10 by QualityIndex:\n",
      "Publication Number  QualityIndex  Top5pct\n",
      "   IN202441071932A      3.512602     True\n",
      "    WO2024256708A2      3.327298     True\n",
      "    AU2024220198A1      3.002016     True\n",
      "   SG11202407258A1      2.958076     True\n",
      "    WO2024186954A2      2.958076     True\n",
      "   IN202441004476A      2.648994     True\n",
      "    AU2023314124A1      2.604123     True\n",
      "       EP4562581A1      2.589477     True\n",
      "    WO2024025863A1      2.589477     True\n",
      "   SG11202407260A1      2.589477     True\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:31:54.033416Z",
     "start_time": "2025-11-12T13:31:54.031312Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f63606ca6240ea6f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
